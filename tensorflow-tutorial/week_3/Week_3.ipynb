{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 3: CNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVHN can be downloaded from http://ufldl.stanford.edu/housenumbers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "train = loadmat('../SVHN/train_32x32.mat')\n",
    "test = loadmat('../SVHN/test_32x32.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train` and `test` are dictionaries with keys `'X'` and `'y'`. The values are numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3, 73257)\n",
      "(73257, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train['X'].shape)\n",
    "print(train['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3, 26032)\n",
      "(26032, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test['X'].shape)\n",
    "print(test['y'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_set = np.transpose(train['X'], (3, 0, 1, 2)).astype(np.float32)\n",
    "training_labels = train['y']\n",
    "\n",
    "test_set = np.transpose(test['X'], (3, 0, 1, 2)).astype(np.float32)\n",
    "test_labels = test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = training_set.shape[0]\n",
    "n_test = test_set.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAGaFJREFUeJztnV+oZeV5xp93rb33OSc6ZebE6AyjVBO8SAiNCQcJWIJN2mAloNImJBfBC8mEEqGB9EIsNBZ6kZQmIRfFMtYhplj/NCpKkTYiKZIbkxNrRpNpGyM2GR2chJkhxs7Ze/15e7GXcBzX+5z976ytfs8PDmef9e1vfe/+9nr33ud79vN+5u4QQqRHtuwAhBDLQckvRKIo+YVIFCW/EImi5BciUZT8QiSKkl+IRFHyC5EoSn4hEqU3T2czuwbANwHkAP7R3b/C7r++vtcPHtwfnW2eUKbCQb7VOFMTaZltqFkDibsYmV86VNxo5DmzcLzunufxaO3jZVn8vhfHvksEUzzLd29ffPFFnD51aqIHMHPym1kO4O8B/BGA4wB+aGaPuPtPoz4HD+7HQw8eic7HRps6vppMXU0ysqrrsC36KnRVV2GfoorPV5E4WIyzfCW7tvhiJ+GjJvPR6/XDtizLW4/nFl9y5u19AP4iyl6E+kGMg8FK3KdPYrQ4RvhsLxrR80mmPuRPrr9u4vvO87H/SgDPufvz7j4CcC+AyUcWQiyVeZL/IIBfbvv7eHNMCPEWYJ7kb/uM84bPL2Z2yMw2zWzz1KkzcwwnhFgk8yT/cQCXbPv7YgAvnXsndz/s7hvuvrG+vneO4YQQi2Se5P8hgMvN7DIzGwD4NIBHFhOWEGK3mXm1391LM7sZwL9jLPUdcfef0E6WIVttX2V1slLqVftqaFGWYZ+KrGAz9aAs42Xl4XDU3ieID+ByTV0TGS1YLQe49lEURevxYbEV9mGyV96PV/RHRft8AIAF6kIvj5ewM8SPmbX189WwDXn79ZYj7pPV8VhM/WDPDJNaZ1FvPFRGJlcc5tL53f1RAI/Ocw4hxHLQN/yESBQlvxCJouQXIlGU/EIkipJfiESZa7V/Wmp3vLrVLkWhjl+HqlG7bjeqYqmvJIYaIxJbTaS+s5HUR+Qfm/H1Nc/jOHpEmquK9n5lQbTPjJh3SPxOHlrU5EyDJeYjdqGS8FHl7edkYWTU5Ujmg5mxEAcZm9CYGau9zzSqod75hUgUJb8QiaLkFyJRlPxCJIqSX4hE6XS132vHcNi+6hmtXgJAMWxXCLixhywBk9X+kpxzNGpf7Welv1h5sjwnRhZaYy5sQhasbveJMaYm58t7cRz93iA+ZzDH1HBFFB+2iM1UBw8eXFWR+oPkfJFhCQDc4+ugLOMHXpF+0441jUlI7/xCJIqSX4hEUfILkShKfiESRckvRKIo+YVIlG6lPlgosUSGFAAIytKhLEldNKKeOKlzVhHdqwrqDBLlkJpwer1YfhuQXWNWV2KJLRqu9HiHGiYr9tlYvficxaj9CRhGxi4AxTCWwyLJDgBqVv8xeHKoCYdpn+Ttkkm+9Szxk4s4uhZl7BFC7IiSX4hEUfILkShKfiESRckvRKIo+YVIlLmkPjN7AcArACoApbtv0A4OeDV9TbVouy4jkl2Wx9tMMfeVM2kuKO5Ws9pzTM4bxDGursUy2jveEbdFLjzL4rnq9eLLoD+IpT6zeMurrbPtDshXfRj2+e3o1bCN1UmsiGOuzNpdmnngfhxDti8jzyeTfJlzr4r0OXK+OrJ2Tr5b10J0/j9w918v4DxCiA7Rx34hEmXe5HcA3zWzH5nZoUUEJITohnk/9l/l7i+Z2YUAHjOz/3L3J7bfoXlROAQA+/fvn3M4IcSimOud391fan6fBPAQgCtb7nPY3TfcfWPvvr3zDCeEWCAzJ7+ZnWdme167DeDjAJ5dVGBCiN1lno/9FwF4qClQ2QPwz+7+bzv2iqotElnDrF0SI6oLeqQ4Jow5CNslqnEckZMqLvrZ68evr2tEzlt7x1rYtroWy2/9fvvjznqskGh8GeRZLEdmiONH4Lgc9mJZLrM4Dve4Hyv+WgUaMivwakbchWELUJEYSyYvR85D+t48vTx4LjMnv7s/D+ADs/YXQiwXSX1CJIqSX4hEUfILkShKfiESRckvRKJ0WsATMGTWLkXlRKPIAqfaYBDLecypxhhl8TnzwL1X1bE8SFQ0rK7Errg10rbSj+W3PJD0jMibYNsaErtlWccOvaoM9mQsmRbF9sFjm/zFeFToktjf2M55VU0kR1bAkxUMDdpIXVLYNJpegN75hUgUJb8QiaLkFyJRlPxCJIqSX4hE6Xi1H4hebzJja6ztMPPOCqk9x7dqYgaSwMATmZXAX11zYmTpZcxsEz/uaBW4LOLHRWvgBav2ADAaxYamsmh/5MMtNlZ8vpoYY6iQEZhmWL09upI+/yL7G08ZreqTBxbFP014eucXIlGU/EIkipJfiERR8guRKEp+IRJFyS9EonQr9TlQBXJZRWSeqMZcRrbWYm1M6ovq9AGxbMTksJy4MypicqkqEgdpqwJJb+tsbMIZjoqwrSzjtmhLLgCoyvbnjNXOGxXxfBA1EhmRPnuBIYiZcDIm3bLrilw75JIj5fiIJD3NvlwBeucXIlGU/EIkipJfiERR8guRKEp+IRJFyS9Eouwo9ZnZEQCfAHDS3d/fHFsHcB+ASwG8AOBT7n56p3M5HHXdLumNRltxkL1gWyjm9GJWLwKT+iKJsCQ6lNfx62tJpD6+BVXYFJ5zi7jptraIZBc5GQEMh7EMGPUri/g5K8hjZvPYH8T1DhHUXcxyIueRNpDrg76TMudh0FYROc8iCXkKBXCSd/5vAbjmnGO3AHjc3S8H8HjztxDiLcSOye/uTwA4dc7h6wDc1dy+C8D1C45LCLHLzPo//0XufgIAmt8XLi4kIUQX7PqCn5kdMrNNM9s8c+bMbg8nhJiQWZP/ZTM7AADN75PRHd39sLtvuPvG3r17ZxxOCLFoZk3+RwDc2Ny+EcDDiwlHCNEVk0h99wC4GsAFZnYcwJcBfAXA/WZ2E4BfAPjkpAOGSgQr4GmBM8tjGYpvurTo/3aIPEjHouU9416k8GeWtceS5/Fc9XtkqzTiYiuIC68OCqFy12QsR5JukZo3bsuD7cuCbc0AIOuRAqlEQo62Bhs3kqZAQs6pbhc8LtLjXHZMfnf/TND0sSnGEUK8ydA3/IRIFCW/EImi5BciUZT8QiSKkl+IROm0gKcBiA1TTEIJZLsZnXtMvsrJ/n+RTMXkq5w4xNhYed4nbYHLEQDQLumtki5s7z8up8b9RsN2p+DZOnYQZha7BGsi3c7URjQxcnkgIxKhsw0AiQM1LihLCs0Gc88k0XPRO78QiaLkFyJRlPxCJIqSX4hEUfILkShKfiESpVupzwx51i5h5fmA9IvPF/Yh8lVGbGCz7P/H+5A4ZmxjEmG/H81v/FRXVawDWhY77dbW1sK2s2fPth7PslfiOIgcNiJ7OVJJLJKDmUzMpL7AJQgAzgp/1qwYZxTL9Nciy4nJzy6EeFuj5BciUZT8QiSKkl+IRFHyC5Eona72AxYaVjKLV7BDnKyGkhV9bqiZfgXeWBE5Ql3Hq9sV2ZMrNoIA0co3f8zEmNSLDUYrK7FC0wsMMGUVm3eGZEW/bhcPAPAV+EiIyfN4Dnt5/LwwE5TTuotka7noOMuJ0GQWd3lDTJPfVQjxdkLJL0SiKPmFSBQlvxCJouQXIlGU/EIkyiTbdR0B8AkAJ939/c2x2wB8DsCvmrvd6u6PTnAuZFk0ZPw6VAe10WpiluCva9Nvg8RgslxJ5KvIhAMAW1tbYRuTc5hsF/ZhdenIPDITSahGsm23mGmGPJ2lx/Nfebu0WBHJsa7jtOgROY/XBWQS8gzvwaxe4IRMMuq3AFzTcvwb7n5F87Nj4gsh3lzsmPzu/gSAUx3EIoTokHn+57/ZzI6a2REz27ewiIQQnTBr8t8O4D0ArgBwAsDXojua2SEz2zSzzdOn9QFCiDcLMyW/u7/s7pWPd9O4A8CV5L6H3X3D3Tf27VufNU4hxIKZKfnN7MC2P28A8OxiwhFCdMUkUt89AK4GcIGZHQfwZQBXm9kVGFvIXgDw+YlGcyDaPcmrWLqog7a6JH1IW0ZqvtVlLBtFbeUolo2YDHiWuAGN1LMrRrHFbRbVqNeLO/WJc28wiC+fUdUucVoWzz0xHoIoZbT2XxXEUZTxc5aXJC0y5iAkTsEe2QYuaiD65vxC3wTJ7+6faTl85wLGFkIsEX3DT4hEUfILkShKfiESRckvRKIo+YVIlE4LeDo8LD7Ji1m2yzVMRqsqUjCRuK+isYDYoTerq68oRmHbcBgHWRMXW0w8H71efBn0iSTW7/9O2BY51XLiZBysroZtK3H4KIq4MdzWirzvsWtnNIqfs14/nkcmccY7h8VxRNcVL+76evTOL0SiKPmFSBQlvxCJouQXIlGU/EIkipJfiETpdq8+d1SRdEScWXnkpCKS12j0f/H58rWwbZXITXv2tI/H5BVWiJPJm6MRkRzr6aW+qAgqAPR6ZO6Jy7Eoz4Rte9+5t/X4+eftCftUxMU2KshjJteOBQU3K+L6JAY85HmcMuWQ7K9YEik72DeQOTTrGa6BN5x/7jMIId6SKPmFSBQlvxCJouQXIlGU/EIkSrer/Wax0SJ2N4Sr4k5W+5n5ha3O56SQXGSAYX1YG9umyVgbcSbVgSmFLQ5XxhpJUxU/Ng/UBWd16YgiUbHVcmKsmqU+HtmtC0SgQV0Rxxjx21jYSJ7nqBbmFMX99M4vRKIo+YVIFCW/EImi5BciUZT8QiSKkl+IRJlku65LAHwbwH6Mi4oddvdvmtk6gPsAXIrxll2fcvfTO5wrlMsyIl9VgRRSETmvqmNjTE30K7O4xlwkv5Fdt5DlpJE85nxGGbC09sddVsO4TzxVqC3WtlZW4628PHrOiCxXkzZn/Yj5KItMYcS8AyeSXU2eF3JKomSHMiDrE29vt9gafiWAL7n7ewF8GMAXzOx9AG4B8Li7Xw7g8eZvIcRbhB2T391PuPtTze1XABwDcBDAdQDuau52F4DrdytIIcTimep/fjO7FMAHATwJ4CJ3PwGMXyAAXLjo4IQQu8fEyW9m5wN4AMAX3f03U/Q7ZGabZrZ5+vSpWWIUQuwCEyW/jVfBHgBwt7s/2Bx+2cwONO0HAJxs6+vuh919w9039u1bX0TMQogFsGPy29hFcieAY+7+9W1NjwC4sbl9I4CHFx+eEGK3mMTVdxWAzwJ4xsyebo7dCuArAO43s5sA/ALAJycZMItcbkQS86JdvmBbYfXK+KE5s2aRLZIskI2MOffI42L14NgWWkZEpaitINtMlaQGHojTLifF7izQP9lWaU4kNtbGYoxmvzerzEr6GYmR9YvGY32yrP05Y9fGueyY/O7+fcQS5scmHkkI8aZC3/ATIlGU/EIkipJfiERR8guRKEp+IRKl0wKeRgp4stehKihKaayo44xtdWxUQyQDRsYxgMt5/X7cNhjEgWREBsxG7fNYIZZFc1YAk7j61lbirc0Gvfb4meeMOt9YT1K1MizWSgtqztaWkdaMWD+jNjaWMyvphOidX4hEUfILkShKfiESRckvRKIo+YVIFCW/EInS7V59QFztkkgvVeDayoibqyZtbD8zZnALiyaSTszFlmVkX8B+XEi0Twpn9gfBfoK9+HW+KGLHH3ti1tbW4jj67TEOh0XYh0mwXs72fEb7PJYzFhK1fAZZEYAxOTK4VpmaxxyEk6J3fiESRckvRKIo+YVIFCW/EImi5BciUZaw2j/9KmVUy4z6QGYYZ6ez1uG2YfEqdVnHK8e5kxp4WRzHyoDUDMzaV9kHpE9RxCvwbAWb1RmMprEidRfLIm6jdRepWyg4Ts7n5PmMtiEDeIw1uRxj71TcialZk6J3fiESRckvRKIo+YVIFCW/EImi5BciUZT8QiTKjlKfmV0C4NsA9mNcxO6wu3/TzG4D8DkAv2ruequ7P7rjiIEhwYk0F7UZ21aJtIG0sTgi+bAgEs+wGMZhkK28KiIRsm2corqAeR736ZFtt2Y1SNVle/zliEh9IyI5EqUvtzj+PGufj34vNk7R7bqoKyxuYluKhRPp5BpegLFnEp2/BPAld3/KzPYA+JGZPda0fcPd/27uKIQQnTPJXn0nAJxobr9iZscAHNztwIQQu8tU//Ob2aUAPgjgyebQzWZ21MyOmNm+BccmhNhFJk5+MzsfwAMAvujuvwFwO4D3ALgC408GXwv6HTKzTTPbPHXq1AJCFkIsgomS38z6GCf+3e7+IAC4+8vuXvn4i9B3ALiyra+7H3b3DXffWF9fX1TcQog52TH5bby0fCeAY+7+9W3HD2y72w0Anl18eEKI3WKS1f6rAHwWwDNm9nRz7FYAnzGzKzAWOF4A8PmJRgwUCqPbD7V3iuqzAUDNJBkGVWSCOKLafgAKIm3lFtfOG43itqKMJbFQtiN7YdGpJxJbQVx4RdXeNhzG0mfFnHZEKmO1EKPt0vKcOSNnk5Azds1RZS6QsomkG8c/uQQ4yWr/94Mz7qzpCyHetOgbfkIkipJfiERR8guRKEp+IRJFyS9EonRcwNNC11yexy6ryMFUEomNSX3MEFWxAp6BtYwVuSxJwcotMlZvK56P3qvx01aU7RIhLbZJJCXmwhtuxXJkOWx39TEJswqcgEA89wBgRCLMAsdfFrj9AC7nMcdfRuaRyXZRTjAJM5Ij2ThvOMfE9xRCvK1Q8guRKEp+IRJFyS9Eoij5hUgUJb8QidL9Xn0BnhEHUyBTMd8ec2ZF7jyAu8ci+ZBJfXUVy1AjIl+d3TobtrHapFtb7XOVkQKehlhSYlJlVRBXZdBUEScgc/Ux12fk3AOAXlDQdLDSvqchAPT7scxqRH4zcl2x6zEq5Mpku6jNpnD16Z1fiERR8guRKEp+IRJFyS9Eoij5hUgUJb8QidKp1OfwWBYjMokFUo6T/ewq4vgrSyYpkaKURXvhTFp4ksg1rADpFnG/laRfBJMH+1ksbVVEqmTSVqRiOtl/jkmmVPbqE/dbUNCU7ZNI94CcYS/HcVvcNMtYofQ5xTh65xciUZT8QiSKkl+IRFHyC5EoSn4hEmXH1X4zWwXwBICV5v7fcfcvm9llAO4FsA7gKQCfdfd4iXp8rnCbIWamiGqZucer/WUVtw2HW2FbXceGjyKoMUcNRmRbKLZoTzw/1GwTGYlYjCUr70eMTnyLtfa2jOz/xVa3M2L8YrtkRWYsVuORqTC8RN4MS/oklozt/hVsv8YUkzecf4L7DAF81N0/gPF23NeY2YcBfBXAN9z9cgCnAdw08ahCiKWzY/L7mN82f/abHwfwUQDfaY7fBeD6XYlQCLErTPQ/v5nlzQ69JwE8BuDnAM64+2ufP48DOLg7IQohdoOJkt/dK3e/AsDFAK4E8N62u7X1NbNDZrZpZpunT52aPVIhxEKZarXf3c8A+A8AHwaw18xeWyq6GMBLQZ/D7r7h7hv71tfniVUIsUB2TH4ze5eZ7W1urwH4QwDHAHwPwJ82d7sRwMO7FaQQYvFMYuw5AOAuM8sxfrG4393/1cx+CuBeM/sbAP8J4M6dTmRmGAzapbToOACsBPXWzg5jyausyDZTRaxIsq28ikBiq4i8kpFtsvKKGTfiOJhuVxGJMzxdrEbCiFQJKgNGx0kNPCIdMsmUGXGibb4Kcn3UZO7ZFlpUZWPGNWuPMcuml0Wnkfp2TH53Pwrggy3Hn8f4/38hxFsQfcNPiERR8guRKEp+IRJFyS9Eoij5hUgUm0YamHsws18B+N/mzwsA/LqzwWMUx+tRHK/nrRbH77r7uyY5YafJ/7qBzTbdfWMpgysOxaE49LFfiFRR8guRKMtM/sNLHHs7iuP1KI7X87aNY2n/8wshlos+9guRKEtJfjO7xsz+28yeM7NblhFDE8cLZvaMmT1tZpsdjnvEzE6a2bPbjq2b2WNm9rPm974lxXGbmb3YzMnTZnZtB3FcYmbfM7NjZvYTM/vz5ninc0Li6HROzGzVzH5gZj9u4vjr5vhlZvZkMx/3mVlshZ0Ed+/0B0COcRmwdwMYAPgxgPd1HUcTywsALljCuB8B8CEAz2479rcAbmlu3wLgq0uK4zYAf9HxfBwA8KHm9h4A/wPgfV3PCYmj0znBuAzw+c3tPoAnMS6gcz+ATzfH/wHAn80zzjLe+a8E8Jy7P+/jUt/3ArhuCXEsDXd/AsC5Nc2uw7gQKtBRQdQgjs5x9xPu/lRz+xWMi8UcRMdzQuLoFB+z60Vzl5H8BwH8ctvfyyz+6QC+a2Y/MrNDS4rhNS5y9xPA+CIEcOESY7nZzI42/xbs+r8f2zGzSzGuH/Ekljgn58QBdDwnXRTNXUbyt5UgWZbkcJW7fwjAHwP4gpl9ZElxvJm4HcB7MN6j4QSAr3U1sJmdD+ABAF909990Ne4EcXQ+Jz5H0dxJWUbyHwdwyba/w+Kfu427v9T8PgngISy3MtHLZnYAAJrfJ5cRhLu/3Fx4NYA70NGcmFkf44S7290fbA53PidtcSxrTpqxpy6aOynLSP4fAri8WbkcAPg0gEe6DsLMzjOzPa/dBvBxAM/yXrvKIxgXQgWWWBD1tWRruAEdzImNC9LdCeCYu399W1OncxLF0fWcdFY0t6sVzHNWM6/FeCX15wD+ckkxvBtjpeHHAH7SZRwA7sH442OB8SehmwC8E8DjAH7W/F5fUhz/BOAZAEcxTr4DHcTx+xh/hD0K4Onm59qu54TE0emcAPg9jIviHsX4heavtl2zPwDwHIB/AbAyzzj6hp8QiaJv+AmRKEp+IRJFyS9Eoij5hUgUJb8QiaLkFyJRlPxCJIqSX4hE+X+Oh5gAUr/uFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ff7321ef0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit: 5\n"
     ]
    }
   ],
   "source": [
    "example = np.random.choice(np.arange(n_train))\n",
    "\n",
    "image = training_set[example]\n",
    "label = training_labels[example][0]\n",
    "\n",
    "if label == 10:\n",
    "    label = 0\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print(\"Digit: {}\".format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the images to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(images):\n",
    "    images = np.add.reduce(images, keepdims=True, axis=3)\n",
    "    images = images / 3.0\n",
    "    return images / 128.0 - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_gs = convert_to_grayscale(training_set)\n",
    "test_set_gs = convert_to_grayscale(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73257, 32, 32, 1)\n",
      "(26032, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "print(training_set_gs.shape)\n",
    "print(test_set_gs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ff7321a90>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit: 4\n"
     ]
    }
   ],
   "source": [
    "example = np.random.choice(np.arange(n_train))\n",
    "\n",
    "image = training_set_gs[example]\n",
    "label = training_labels[example][0]\n",
    "\n",
    "if label == 10:\n",
    "    label = 0\n",
    "\n",
    "plt.imshow(np.squeeze(image), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Digit: {}\".format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't flatten the inputs! Use a CNN to process the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set_flat = training_set_gs.reshape((n_train, -1))\n",
    "# test_set_flat = test_set_gs.reshape((n_test, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the labels as one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels):\n",
    "    \"\"\"\n",
    "    Encodes the labels as one-hot vectors. Zero is represented as 10 in SVHN.\n",
    "    [10] -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    [2] -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    \"\"\"\n",
    "    labels = np.squeeze(labels)\n",
    "    one_hot_labels = []\n",
    "    for num in labels:\n",
    "        one_hot = [0.0] * 10\n",
    "        if num == 10:\n",
    "            one_hot[0] = 1.0\n",
    "        else:\n",
    "            one_hot[num] = 1.0\n",
    "        one_hot_labels.append(one_hot)\n",
    "    labels = np.array(one_hot_labels).astype(np.float32)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels_one_hot = one_hot(training_labels)\n",
    "test_labels_one_hot = one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73257, 10)\n",
      "(26032, 10)\n"
     ]
    }
   ],
   "source": [
    "print(training_labels_one_hot.shape)\n",
    "print(test_labels_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN_CNN:\n",
    "    def __init__(self, wd_factor, learning_rate):\n",
    "        self.wd_factor = wd_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_pointer = 0\n",
    "        self.test_pointer = 0\n",
    "        \n",
    "        self.input = tf.placeholder(dtype=tf.float32, shape=[None, 32, 32, 1], name='input')\n",
    "        self.ground_truth = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='ground_truth')\n",
    "        \n",
    "        # For batch norm and dropout\n",
    "        self.is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        print(self.input)\n",
    "        \n",
    "        self._build_graph()\n",
    "        \n",
    "    def _build_graph(self):\n",
    "        weights = []  # for weight decay\n",
    "        \n",
    "        with tf.variable_scope('layers'):\n",
    "            h = tf.layers.conv2d(self.input, 32, (11, 11), strides=(4, 4), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv1')\n",
    "            print(h)\n",
    "            \n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.conv2d(h, 64, (5, 5), strides=(1, 1), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv2')\n",
    "            \n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.conv2d(h, 64, (3, 3), strides=(1, 1), padding='same', \n",
    "                                 data_format='channels_last', activation=None, use_bias=True,\n",
    "                                 kernel_initializer=tf.glorot_uniform_initializer(), name='conv3')\n",
    "            \n",
    "            # Downsample\n",
    "            h = tf.layers.max_pooling2d(h, (2, 2), (2, 2), padding='valid', name='pool1')\n",
    "            print(h)\n",
    "            \n",
    "            # Fully connected layers\n",
    "            h = tf.layers.batch_normalization(h, training=self.is_training)\n",
    "            h = tf.nn.relu(h)\n",
    "            h = tf.layers.flatten(h)\n",
    "            print(h)\n",
    "            \n",
    "            h = tf.layers.dense(h, 32, kernel_initializer=tf.glorot_uniform_initializer(), \n",
    "                                activation=tf.nn.relu, name='dense1')\n",
    "            print(h)\n",
    "            h = tf.layers.dropout(h, rate=0.25, training=self.is_training, name='dropout1')\n",
    "            print(h)\n",
    "            \n",
    "            self.logits = tf.layers.dense(h, 10, kernel_initializer=tf.glorot_uniform_initializer(), \n",
    "                                          activation=tf.identity, name='dense2')\n",
    "            print(self.logits)\n",
    "            self.prediction = tf.nn.softmax(self.logits, name='softmax_prediction')\n",
    "            \n",
    "        with tf.name_scope('loss'):\n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, \n",
    "                                                                                  labels=self.ground_truth))\n",
    "            self.loss += self.weight_decay()\n",
    "            \n",
    "        self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            self.train_op = self.optimizer.minimize(self.loss)\n",
    "            \n",
    "    def weight_decay(self):\n",
    "        loss = 0\n",
    "        for v in tf.global_variables():\n",
    "            if 'Adam' in v.name:\n",
    "                continue\n",
    "            elif 'kernel' in v.name:\n",
    "                loss += self.wd_factor * tf.nn.l2_loss(v)\n",
    "        print(loss)\n",
    "        return loss\n",
    "    \n",
    "    def train_minibatch(self, samples, labels, batch_size):\n",
    "        if self.train_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.train_pointer: self.train_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.train_pointer: self.train_pointer + batch_size]\n",
    "            self.train_pointer += batch_size\n",
    "        else:\n",
    "            samples_minibatch = samples[self.train_pointer:]\n",
    "            labels_minibatch = labels[self.train_pointer: self.train_pointer + batch_size]\n",
    "            self.train_pointer = 0\n",
    "        return samples_minibatch, labels_minibatch\n",
    "\n",
    "    def train(self, train_samples, train_labels, train_batch_size, iteration_steps):\n",
    "        print('Start Training')\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "            for i in range(iteration_steps):\n",
    "                samples, labels = self.train_minibatch(train_samples, train_labels, train_batch_size)\n",
    "                \n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: True}\n",
    "                _, loss = sess.run([self.train_op, self.loss], feed_dict=feed_dict)\n",
    "                \n",
    "                if i % 50 == 0:\n",
    "                    print(\"Minibatch loss at step {}: {}\".format(i, loss))\n",
    "                    losses.append([i, loss])\n",
    "                    \n",
    "            saver.save(sess, './model')\n",
    "        return losses\n",
    "                    \n",
    "    def test_minibatch(self, samples, labels, batch_size):\n",
    "        if self.test_pointer + batch_size <= samples.shape[0]:\n",
    "            samples_minibatch = samples[self.test_pointer: self.test_pointer + batch_size]\n",
    "            labels_minibatch = labels[self.test_pointer: self.test_pointer + batch_size]\n",
    "            self.test_pointer += batch_size\n",
    "            end_of_epoch = False\n",
    "        else:\n",
    "            samples_minibatch = samples[self.test_pointer:]\n",
    "            labels_minibatch = labels[self.test_pointer: self.test_pointer + batch_size]\n",
    "            self.test_pointer = 0\n",
    "            end_of_epoch = True\n",
    "        return samples_minibatch, labels_minibatch, end_of_epoch\n",
    "            \n",
    "    def test(self, test_samples, test_labels, test_batch_size):\n",
    "        self.test_pointer = 0\n",
    "        end_of_epoch = False\n",
    "        losses = []\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "            saver.restore(sess, './model')\n",
    "            while not end_of_epoch:\n",
    "                samples, labels, end_of_epoch = self.test_minibatch(test_samples, test_labels, test_batch_size)\n",
    "                feed_dict = {self.input: samples, self.ground_truth: labels, self.is_training: False}\n",
    "                losses.append(sess.run(self.loss, feed_dict=feed_dict))  \n",
    "        print(\"Average test loss: {}\".format(np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input:0\", shape=(?, 32, 32, 1), dtype=float32)\n",
      "Tensor(\"layers/conv1/BiasAdd:0\", shape=(?, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"layers/pool1/MaxPool:0\", shape=(?, 4, 4, 64), dtype=float32)\n",
      "Tensor(\"layers/flatten/Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"layers/dense1/Relu:0\", shape=(?, 32), dtype=float32)\n",
      "Tensor(\"layers/dropout1/cond/Merge:0\", shape=(?, 32), dtype=float32)\n",
      "Tensor(\"layers/dense2/Identity:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"loss/add_4:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "WD_FACTOR = 0.0\n",
    "LEARNING_RATE = 0.001\n",
    "model = SVHN_CNN(WD_FACTOR, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'layers/conv1/kernel:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/moving_mean:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/moving_variance:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/moving_mean:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/moving_variance:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel:0' shape=(1024, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/kernel/Adam:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/kernel/Adam_1:0' shape=(11, 11, 1, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv1/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/gamma/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization/beta/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel/Adam:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/kernel/Adam_1:0' shape=(5, 5, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv2/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/gamma/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_1/beta/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel/Adam:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/kernel/Adam_1:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/conv3/bias/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/gamma/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta/Adam:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/batch_normalization_2/beta/Adam_1:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel/Adam:0' shape=(1024, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/kernel/Adam_1:0' shape=(1024, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense1/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel/Adam:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/kernel/Adam_1:0' shape=(32, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias/Adam:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'layers/dense2/bias/Adam_1:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "Minibatch loss at step 0: 2.8680355548858643\n",
      "Minibatch loss at step 50: 2.110264778137207\n",
      "Minibatch loss at step 100: 1.7394347190856934\n",
      "Minibatch loss at step 150: 1.4298322200775146\n",
      "Minibatch loss at step 200: 0.9910917282104492\n",
      "Minibatch loss at step 250: 1.129537582397461\n",
      "Minibatch loss at step 300: 0.7910434007644653\n",
      "Minibatch loss at step 350: 1.016052007675171\n",
      "Minibatch loss at step 400: 0.921546220779419\n",
      "Minibatch loss at step 450: 0.7227210402488708\n",
      "Minibatch loss at step 500: 0.7619926333427429\n",
      "Minibatch loss at step 550: 0.7269459366798401\n",
      "Minibatch loss at step 600: 0.5330272316932678\n",
      "Minibatch loss at step 650: 0.7307744026184082\n",
      "Minibatch loss at step 700: 0.6686570644378662\n",
      "Minibatch loss at step 750: 0.7053372859954834\n",
      "Minibatch loss at step 800: 0.4050430655479431\n",
      "Minibatch loss at step 850: 0.703396201133728\n",
      "Minibatch loss at step 900: 0.5636864304542542\n",
      "Minibatch loss at step 950: 0.728124737739563\n",
      "Minibatch loss at step 1000: 0.4723033607006073\n",
      "Minibatch loss at step 1050: 0.7759133577346802\n",
      "Minibatch loss at step 1100: 0.346706360578537\n",
      "Minibatch loss at step 1150: 0.6537039875984192\n",
      "Minibatch loss at step 1200: 0.6924225091934204\n",
      "Minibatch loss at step 1250: 0.6016758680343628\n",
      "Minibatch loss at step 1300: 0.41526204347610474\n",
      "Minibatch loss at step 1350: 0.6537725329399109\n",
      "Minibatch loss at step 1400: 0.4832175374031067\n",
      "Minibatch loss at step 1450: 0.46493521332740784\n",
      "Minibatch loss at step 1500: 0.4732118248939514\n",
      "Minibatch loss at step 1550: 0.40400904417037964\n",
      "Minibatch loss at step 1600: 0.5886425971984863\n",
      "Minibatch loss at step 1650: 0.6886410713195801\n",
      "Minibatch loss at step 1700: 0.39379289746284485\n",
      "Minibatch loss at step 1750: 0.39117860794067383\n",
      "Minibatch loss at step 1800: 0.26820990443229675\n",
      "Minibatch loss at step 1850: 0.4756115674972534\n",
      "Minibatch loss at step 1900: 0.43099406361579895\n",
      "Minibatch loss at step 1950: 0.3297615051269531\n",
      "Minibatch loss at step 2000: 0.4207484722137451\n",
      "Minibatch loss at step 2050: 0.3530750870704651\n",
      "Minibatch loss at step 2100: 0.5484875440597534\n",
      "Minibatch loss at step 2150: 0.33951157331466675\n",
      "Minibatch loss at step 2200: 0.40837132930755615\n",
      "Minibatch loss at step 2250: 0.3575775921344757\n",
      "Minibatch loss at step 2300: 0.4293573200702667\n",
      "Minibatch loss at step 2350: 0.45247575640678406\n",
      "Minibatch loss at step 2400: 0.5104183554649353\n",
      "Minibatch loss at step 2450: 0.3783853352069855\n",
      "Minibatch loss at step 2500: 0.4153708219528198\n",
      "Minibatch loss at step 2550: 0.37989217042922974\n",
      "Minibatch loss at step 2600: 0.5662011504173279\n",
      "Minibatch loss at step 2650: 0.3685383200645447\n",
      "Minibatch loss at step 2700: 0.40489962697029114\n",
      "Minibatch loss at step 2750: 0.27248597145080566\n",
      "Minibatch loss at step 2800: 0.28475528955459595\n",
      "Minibatch loss at step 2850: 0.3206775486469269\n",
      "Minibatch loss at step 2900: 0.2724637985229492\n",
      "Minibatch loss at step 2950: 0.43288013339042664\n",
      "Minibatch loss at step 3000: 0.4107995629310608\n",
      "Minibatch loss at step 3050: 0.4739113450050354\n",
      "Minibatch loss at step 3100: 0.38877061009407043\n",
      "Minibatch loss at step 3150: 0.23355981707572937\n",
      "Minibatch loss at step 3200: 0.39540931582450867\n",
      "Minibatch loss at step 3250: 0.26778286695480347\n",
      "Minibatch loss at step 3300: 0.48973116278648376\n",
      "Minibatch loss at step 3350: 0.42380180954933167\n",
      "Minibatch loss at step 3400: 0.37192749977111816\n",
      "Minibatch loss at step 3450: 0.42020922899246216\n",
      "Minibatch loss at step 3500: 0.2975406050682068\n",
      "Minibatch loss at step 3550: 0.2706596553325653\n",
      "Minibatch loss at step 3600: 0.28694844245910645\n",
      "Minibatch loss at step 3650: 0.3557276725769043\n",
      "Minibatch loss at step 3700: 0.21399885416030884\n",
      "Minibatch loss at step 3750: 0.270393431186676\n",
      "Minibatch loss at step 3800: 0.2507953643798828\n",
      "Minibatch loss at step 3850: 0.40125226974487305\n",
      "Minibatch loss at step 3900: 0.2589300274848938\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE = 128\n",
    "ITERATIONS = 10000\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "losses = model.train(training_set_gs, training_labels_one_hot, TRAIN_BATCH_SIZE, ITERATIONS)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Training time: {}s\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    losses = np.array(losses)\n",
    "    np.save('./train_losses.npy', losses)\n",
    "    print(losses.shape)\n",
    "except NameError:\n",
    "    losses = np.load('./train_losses.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = losses[:, 0]\n",
    "train_loss = losses[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, train_loss, 'b-')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test network predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 128\n",
    "\n",
    "model.test(test_set_gs, test_labels_one_hot, TEST_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.random.choice(np.arange(n_test))\n",
    "\n",
    "sample = np.expand_dims(test_set_gs[example], axis=0)\n",
    "label = np.expand_dims(test_labels_one_hot[example], axis=0)\n",
    "\n",
    "digit = np.where(label[0]==1.0)[0][0]\n",
    "\n",
    "feed_dict = {model.input: sample, model.ground_truth: label, model.is_training: False}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "    saver.restore(sess, './model')\n",
    "    prediction = sess.run(model.prediction, feed_dict=feed_dict)[0]\n",
    "\n",
    "image = np.reshape(sample, (32, 32))\n",
    "\n",
    "print(\"Test sample digit: {}\".format(digit))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(17, 5))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title(\"Test example\")\n",
    "\n",
    "classes = np.arange(10)\n",
    "width = 1.0\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "ax[1].bar(classes, prediction, width, color='Blue')\n",
    "ax[1].set_ylabel('Probabilities')\n",
    "ax[1].set_title('Network categorical distribution')\n",
    "ax[1].set_xticks(classes)\n",
    "ax[1].set_xticklabels(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'))\n",
    "ax[1].set_xlabel('Digit class')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Network prediction probabilities:\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
